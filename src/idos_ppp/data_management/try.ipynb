{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.copy_on_write = True\n",
    "pd.options.future.infer_string = True\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "\n",
    "current_dir = Path(os.getcwd())\n",
    "\n",
    "PROJECT = current_dir.parent.resolve()\n",
    "SRC = PROJECT.parent.resolve()\n",
    "ROOT = PROJECT.joinpath(\"..\", \"..\").resolve()\n",
    "\n",
    "BLD = ROOT.joinpath(\"bld\").resolve()\n",
    "\n",
    "# Folders inside idos_ppp\n",
    "DATA = PROJECT.joinpath(\"data\").resolve()\n",
    "DATA_MGT = PROJECT.joinpath(\"data_management\").resolve()\n",
    "ANALYSIS = PROJECT.joinpath(\"analysis\").resolve()\n",
    "FINAL = PROJECT.joinpath(\"final\").resolve()\n",
    "\n",
    "DOCUMENTS = ROOT.joinpath(\"documents\").resolve()\n",
    "\n",
    "print(ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE ORIGINAL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idos_ppp.config import DATA\n",
    "from idos_ppp.parameters import sheet_names\n",
    "\n",
    "data_file = DATA\n",
    "raw_data_path = DATA / \"Data_2007_2010_2013_2016_2019.xlsx\"\n",
    "\n",
    "# Open the dataset file using pandas\n",
    "try:\n",
    "    raw_dta = {\n",
    "        sheet: pd.read_excel(raw_data_path, sheet_name=sheet, header=1)\n",
    "        for sheet in sheet_names\n",
    "    }\n",
    "    print(\"Data loaded successfully.\")\n",
    "    # Display the first few rows of one of the dataframes\n",
    "    for sheet, df in raw_dta.items():\n",
    "        print(f\"First few rows of {sheet}:\")\n",
    "        print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {raw_data_path} was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def are_csv_files_identical(file_path1, file_path2):\n",
    "    \"\"\"Check if two CSV files are identical.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path1: str or Path, path to the first CSV file.\n",
    "    - file_path2: str or Path, path to the second CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if the files are identical, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV files into DataFrames\n",
    "        df1 = pd.read_csv(file_path1)\n",
    "        df2 = pd.read_csv(file_path2)\n",
    "\n",
    "        # Compare the DataFrames\n",
    "        return df1.equals(df2)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Example usage\n",
    "directory = Path(BLD / \"data\")  # Replace with your directory path\n",
    "file1 = directory / \"clean_data_new.csv\"\n",
    "file2 = directory / \"clean_data.csv\"\n",
    "\n",
    "if are_csv_files_identical(file1, file2):\n",
    "    print(\"The CSV files are identical.\")\n",
    "else:\n",
    "    print(\"The CSV files are not identical.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE CLEANED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_2 = pd.read_csv(BLD / \"data\" / \"clean_data.csv\")\n",
    "clean_data_2.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_2.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBSETS, ANALYSIS AND PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrames\n",
    "output_dir = BLD / \"data\" / \"subsets\"\n",
    "european_union_countries_data = pd.read_pickle(\n",
    "    output_dir / \"european_union_countries_data.pkl\",\n",
    ")\n",
    "european_union_countries_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.read_pickle(BLD / \"data\" / \"merged_data.pkl\")\n",
    "# print(merged_data.head())\n",
    "print(merged_data.columns)\n",
    "print(len(merged_data.columns))\n",
    "# print(merged_data.describe())\n",
    "# print(merged_data.dtypes)\n",
    "# print(merged_data.shape)\n",
    "# print(merged_data.isnull().sum()) # To see if there are any missing values in the dataset.\n",
    "# for column in merged_data.select_dtypes(include=['object']).columns:\n",
    "#     print(f\"Unique values in {column}: {merged_data[column].unique()}\") # If you have categorical columns, you might want to see the unique values.\n",
    "# float_columns = merged_data.select_dtypes(include=['float64'])\n",
    "# correlation_matrix = float_columns.corr()\n",
    "# print(correlation_matrix)\n",
    "# print(merged_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def are_feather_files_identical(file_path1, file_path2):\n",
    "    \"\"\"Check if two CSV files are identical.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path1: str or Path, path to the first CSV file.\n",
    "    - file_path2: str or Path, path to the second CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if the files are identical, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV files into DataFrames\n",
    "        df1 = pd.read_feather(file_path1)\n",
    "        df2 = pd.read_feather(file_path2)\n",
    "\n",
    "        # Compare the DataFrames\n",
    "        return df1.equals(df2)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Example usage\n",
    "directory = Path(BLD / \"analysis\")  # Replace with your directory path\n",
    "file1 = directory / \"yearly_correlations_continent.arrow\"\n",
    "file2 = directory / \"yearly_continent_correlations.arrow\"\n",
    "\n",
    "if are_feather_files_identical(file1, file2):\n",
    "    print(\"The arrow files are identical.\")\n",
    "else:\n",
    "    print(\"The arrow files are not identical.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova3_stat_yrl_data = pd.read_pickle(\n",
    "    BLD\n",
    "    / \"analysis\"\n",
    "    / \"prot_prov_correlations\"\n",
    "    / \"yearly_prot_prov_continent_correlations.pkl\",\n",
    ")\n",
    "prova3_stat_yrl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idos_ppp.parameters import country_lists\n",
    "\n",
    "inputs_stat_plots = {\n",
    "    list_name: BLD\n",
    "    / \"analysis\"\n",
    "    / \"statistical_analysis\"\n",
    "    / f\"{list_name}_yearly_statistics.pkl\"\n",
    "    for list_name in country_lists.keys()\n",
    "}\n",
    "inputs_stat_plots[\"merged_dataframe_countries\"] = (\n",
    "    BLD / \"analysis\" / \"statistical_analysis\" / \"merged_dataframe_yearly_statistics.pkl\"\n",
    ")\n",
    "\n",
    "inputs_stat_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idos_ppp.parameters import country_lists\n",
    "\n",
    "prova3_data = pd.read_pickle(\n",
    "    BLD / \"data\" / \"subsets\" / \"conflict_and_postconflict_countries_data.pkl\",\n",
    ")\n",
    "prova3_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_and_postconflict_countries_data = pd.read_pickle(\n",
    "    BLD / \"data\" / \"subsets\" / \"conflict_and_postconflict_countries_data.pkl\",\n",
    ")\n",
    "conflict_and_postconflict_countries_data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
