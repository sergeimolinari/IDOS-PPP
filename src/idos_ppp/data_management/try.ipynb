{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.copy_on_write = True\n",
    "pd.options.future.infer_string = True\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "\n",
    "current_dir = Path(os.getcwd())\n",
    "\n",
    "PROJECT = current_dir.parent.resolve()\n",
    "SRC = PROJECT.parent.resolve()\n",
    "ROOT = PROJECT.joinpath(\"..\", \"..\").resolve()\n",
    "\n",
    "BLD = ROOT.joinpath(\"bld\").resolve()\n",
    "\n",
    "# Folders inside idos_ppp\n",
    "DATA = PROJECT.joinpath(\"data\").resolve()\n",
    "DATA_MGT = PROJECT.joinpath(\"data_management\").resolve()\n",
    "ANALYSIS = PROJECT.joinpath(\"analysis\").resolve()\n",
    "FINAL = PROJECT.joinpath(\"final\").resolve()\n",
    "\n",
    "DOCUMENTS = ROOT.joinpath(\"documents\").resolve()\n",
    "\n",
    "print(ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRY THE NEW DATASET FOR POSSIBLE ERRORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idos_ppp.config import DATA\n",
    "from idos_ppp.parameters import sheet_names\n",
    "\n",
    "data_file = DATA\n",
    "raw_data_path = DATA / \"Data_2007_2010_2013_2016_2019.xlsx\"\n",
    "\n",
    "# Open the dataset file using pandas\n",
    "try:\n",
    "    raw_dta = {\n",
    "        sheet: pd.read_excel(raw_data_path, sheet_name=sheet, header=1)\n",
    "        for sheet in sheet_names\n",
    "    }\n",
    "    print(\"Data loaded successfully.\")\n",
    "    # Display the first few rows of one of the dataframes\n",
    "    for sheet, df in raw_dta.items():\n",
    "        print(f\"First few rows of {sheet}:\")\n",
    "        print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {raw_data_path} was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_csv_files_identical(file_path1, file_path2):\n",
    "    \"\"\"Check if two CSV files are identical.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path1: str or Path, path to the first CSV file.\n",
    "    - file_path2: str or Path, path to the second CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if the files are identical, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV files into DataFrames\n",
    "        df1 = pd.read_csv(file_path1)\n",
    "        df2 = pd.read_csv(file_path2)\n",
    "\n",
    "        # Compare the DataFrames\n",
    "        return df1.equals(df2)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Example usage\n",
    "directory = Path(BLD / \"data\")  # Replace with your directory path\n",
    "file1 = directory / \"clean_data_new.csv\"\n",
    "file2 = directory / \"clean_data.csv\"\n",
    "\n",
    "if are_csv_files_identical(file1, file2):\n",
    "    print(\"The CSV files are identical.\")\n",
    "else:\n",
    "    print(\"The CSV files are not identical.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_2 = pd.read_csv(BLD / \"data\" / \"clean_data.csv\")\n",
    "clean_data_2.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_2.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idos_ppp.parameters import middle_east_north_africa_countries\n",
    "\n",
    "# Check if a particular country is in the \"country_name\" column\n",
    "for country in middle_east_north_africa_countries:\n",
    "    if country in clean_data_2[\"country_name\"].values:\n",
    "        print(f\"{country} is in the Country column.\")\n",
    "    else:\n",
    "        print(f\"{country} is not in the Country column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLAY WITH LISTS OF COUNTRIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "european_union = [\n",
    "    \"Austria\",\n",
    "    \"Belgium\",\n",
    "    \"Bulgaria\",\n",
    "    \"Croatia\",\n",
    "    \"Cyprus\",\n",
    "    \"Czech Republic\",\n",
    "    \"Denmark\",\n",
    "    \"Estonia\",\n",
    "    \"Finland\",\n",
    "    \"France\",\n",
    "    \"Germany\",\n",
    "    \"Greece\",\n",
    "    \"Hungary\",\n",
    "    \"Ireland\",\n",
    "    \"Italy\",\n",
    "    \"Latvia\",\n",
    "    \"Lithuania\",\n",
    "    \"Luxembourg\",\n",
    "    \"Malta\",\n",
    "    \"Netherlands\",\n",
    "    \"Poland\",\n",
    "    \"Portugal\",\n",
    "    \"Romania\",\n",
    "    \"Slovak Republic\",\n",
    "    \"Slovenia\",\n",
    "    \"Spain\",\n",
    "    \"Sweden\",\n",
    "]\n",
    "len(european_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conflic / Post-conflict (from Heydemann 2025)\n",
    "conflict_countries = [\"Libya\", \"Syrian Arab Republic\", \"Yemen, Rep.\"]\n",
    "\n",
    "conflict_and_postconflict_countries = [\n",
    "    \"Iraq\",\n",
    "    \"Lebanon\",\n",
    "    \"Libya\",\n",
    "    \"Syrian Arab Republic\",\n",
    "    \"Yemen, Rep.\",\n",
    "]\n",
    "\n",
    "# GCC countries (and repressive ones) (from Heydemann 2025)\n",
    "gcc_high_income_countries = [\n",
    "    \"Bahrain\",\n",
    "    \"Kuwait\",\n",
    "    \"Oman\",\n",
    "    \"Qatar\",\n",
    "    \"Saudi Arabia\",\n",
    "    \"United Arab Emirates\",\n",
    "]\n",
    "\n",
    "repressive_countries = [\n",
    "    \"Egypt, Arab Rep.\",\n",
    "    \"Jordan\",\n",
    "    \"Morocco\",\n",
    "    \"Tunisia\",\n",
    "]  # Tunisia post-2020\n",
    "\n",
    "gcc_and_repressive_countries = [\n",
    "    \"Bahrain\",\n",
    "    \"Kuwait\",\n",
    "    \"Oman\",\n",
    "    \"Qatar\",\n",
    "    \"Saudi Arabia\",\n",
    "    \"United Arab Emirates\",\n",
    "    \"Egypt, Arab Rep.\",\n",
    "    \"Jordan\",\n",
    "    \"Morocco\",\n",
    "    \"Tunisia\",\n",
    "]  # Tunisia post-2020\n",
    "\n",
    "country_lists = {\n",
    "    \"conflict_countries\": conflict_countries,\n",
    "    \"conflict_and_postconflict_countries\": conflict_and_postconflict_countries,\n",
    "    \"gcc_high_income_countries\": gcc_high_income_countries,\n",
    "    \"repressive_countries\": repressive_countries,\n",
    "    \"gcc_and_repressive_countries\": gcc_and_repressive_countries,\n",
    "}\n",
    "print(\n",
    "    *[\n",
    "        len(\n",
    "            [\n",
    "                country\n",
    "                for country in country_list\n",
    "                if country in clean_data_2[\"country_name\"].values\n",
    "            ]\n",
    "        )\n",
    "        for country_list in country_lists.values()\n",
    "    ],\n",
    "    sep=\", \",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check Merged Dataset\n",
    "\n",
    "\n",
    "# Define the file paths\n",
    "pkl_file_path = BLD / \"data\" / \"merged_data.pkl\"\n",
    "csv_file_path = BLD / \"data\" / \"merged_data.csv\"\n",
    "\n",
    "# Load the .pkl file\n",
    "df = pd.read_pickle(pkl_file_path)\n",
    "\n",
    "# Save as CSV\n",
    "df.to_csv(csv_file_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(list(df[\"country_name\"]))\n",
    "\n",
    "\n",
    "for country in european_union:\n",
    "    if country in df[\"country_name\"].values:\n",
    "        print(f\"{country} is in the Country column.\")\n",
    "    else:\n",
    "        print(f\"{country} is not in the Country column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrames\n",
    "output_dir = BLD / \"data\" / \"subsets\"\n",
    "european_union_countries_data = pd.read_pickle(\n",
    "    output_dir / \"european_union_countries_data.pkl\"\n",
    ")\n",
    "european_union_countries_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.read_pickle(BLD / \"data\" / \"merged_data.pkl\")\n",
    "# print(merged_data.head())\n",
    "print(merged_data.columns)\n",
    "print(len(merged_data.columns))\n",
    "# print(merged_data.describe())\n",
    "# print(merged_data.dtypes)\n",
    "# print(merged_data.shape)\n",
    "# print(merged_data.isnull().sum()) # To see if there are any missing values in the dataset.\n",
    "# for column in merged_data.select_dtypes(include=['object']).columns:\n",
    "#     print(f\"Unique values in {column}: {merged_data[column].unique()}\") # If you have categorical columns, you might want to see the unique values.\n",
    "# float_columns = merged_data.select_dtypes(include=['float64'])\n",
    "# correlation_matrix = float_columns.corr()\n",
    "# print(correlation_matrix)\n",
    "# print(merged_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idos_ppp.analysis.idos_dataanalysis import (\n",
    "    calculate_yearly_prot_prov_continent_correlations,\n",
    "    calculate_yearly_prot_prov_correlations,\n",
    ")\n",
    "\n",
    "# Display the DataFrames\n",
    "input_dir = BLD / \"data\" / \"subsets\"\n",
    "output_dir_1 = BLD / \"analysis\" / \"yearly_prot_prov_correlations.arrow\"\n",
    "output_dir_2 = BLD / \"analysis\" / \"yearly_prot_prov_correlations_continent.arrow\"\n",
    "\n",
    "\n",
    "try:\n",
    "    european_union_countries_data = pd.read_pickle(\n",
    "        input_dir / \"european_union_countries_data.pkl\"\n",
    "    )\n",
    "    yearly_correlations_df = calculate_yearly_prot_prov_correlations(\n",
    "        european_union_countries_data\n",
    "    )\n",
    "    yearly_correlations_continent_df = (\n",
    "        calculate_yearly_prot_prov_continent_correlations(european_union_countries_data)\n",
    "    )\n",
    "    yearly_correlations_df.to_feather(output_dir_1)\n",
    "    yearly_correlations_continent_df.to_feather(output_dir_2)\n",
    "    print(\"Data loaded successfully.\")\n",
    "    # Display the first few rows of the dataframe\n",
    "    print(yearly_correlations_df, yearly_correlations_continent_df)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {input_dir} was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_feather_files_identical(file_path1, file_path2):\n",
    "    \"\"\"Check if two CSV files are identical.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path1: str or Path, path to the first CSV file.\n",
    "    - file_path2: str or Path, path to the second CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if the files are identical, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV files into DataFrames\n",
    "        df1 = pd.read_feather(file_path1)\n",
    "        df2 = pd.read_feather(file_path2)\n",
    "\n",
    "        # Compare the DataFrames\n",
    "        return df1.equals(df2)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Example usage\n",
    "directory = Path(BLD / \"analysis\")  # Replace with your directory path\n",
    "file1 = directory / \"yearly_correlations_continent.arrow\"\n",
    "file2 = directory / \"yearly_continent_correlations.arrow\"\n",
    "\n",
    "if are_feather_files_identical(file1, file2):\n",
    "    print(\"The arrow files are identical.\")\n",
    "else:\n",
    "    print(\"The arrow files are not identical.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
